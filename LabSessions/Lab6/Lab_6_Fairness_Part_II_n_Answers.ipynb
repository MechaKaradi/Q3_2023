{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 6 - Operational Fairness in DA/ML\n",
        "Week 6 - Q3, 22/23 <br>\n",
        "SEN163B: Responsible Data Analytics<br>\n",
        " "
      ],
      "metadata": {
        "id": "6g6YXEhab45J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By <b> Nadia Metoui* </b> <br>\n",
        "TA <b> Darsh Modi</b> <br> \n",
        "Faculty of Technology, Policy, and Management (TPM)<br>"
      ],
      "metadata": {
        "id": "pSJOyGv7cFgL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Learning Objectives***<br>\n",
        "At the end of this lab, you will be able to \n",
        "\n",
        "- Use data analytics tools to measure disaparities in a Data Analytics Project\n",
        "- Use data analytics tools to mitigate disaparities in a Data Analytics Project\n"
      ],
      "metadata": {
        "id": "D517eJw7jtwU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Structure***\n",
        "- Part I. Measuring Disparities with Aequitas (See notebook for Part I)\n",
        "- Part II Mitigating Bias/Disparities with FAI360 \n",
        "- Part III: Mitigating Bias/Disparities with FairLearn (a tutorial will be provided for homework exploration)\n"
      ],
      "metadata": {
        "id": "d0t8WNfupsvU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part II: Mitigating Bias with FAI360"
      ],
      "metadata": {
        "id": "PW9WOVdukAgA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huVKV7ODbfBJ"
      },
      "source": [
        "*Acknowledgement: Part II of this assignment is loosely based on the code developed by <i><b>Agathe Balayn</b></i> and <i><b>Seda Gürses</b></i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "not8yuTKbfBJ"
      },
      "source": [
        "In this part of the lab you will be requested to take a closer look at the data and identify and mitigate biases. We will use some tools form <i><b>AIF360 toolkit</b></i><br>(https://aif360.mybluemix.net/) a toolkit developed by IBM to detect and mitigate \"bias\" and \"unfairness\".\n",
        "\n",
        "We will mainely focus on the pakages:\n",
        "- `aif360.metrics.BinaryLabelDatasetMetric`: Metrics used to assess bias in the dataset before training. You will see examples with `mean_difference` and `disparate_impact`\n",
        "- `aif360.metrics.ClassificationMetric`: Metrics used to assess bias in outcomes of the model You will see examples with `mean_difference` and `disparate_impact` and `false_discovery_rate_ratio`\n",
        "- `aif360.algorithms.preprocessing` Bias mitigating algorithm to be applied to a data set before training the model. You will see an example with the `Reweighing` algorithm. \n",
        "\n",
        "You are encouraged to explore AIF360 Library more and use adequate metrics and algorithmes in your analysis byond what we see in this Lab. yu can access AIF360 library documentation [HERE](https://aif360.readthedocs.io/en/stable/index.html) and the AIF360 project page [HERE](https://aif360.mybluemix.net/). Take a close look to both!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps of Part II\n",
        "- Step 0: Set-up (Provided)\n",
        "- Step 1: Pre-processing Biases: Identify and Mitigate\n",
        "- Step 2: In-processing Biases: Identify and Mitigate"
      ],
      "metadata": {
        "id": "xCMRnP2ngP9E"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMgoUm1HbfBK"
      },
      "source": [
        "### Setp 0: Set-up\n",
        "\n",
        "You first need to install the required libraries for this part.  The main libraries are the `aif360` and `sklearn` ones. We also recommend using `numpy` or `pandas` to easily manipulate and explore the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ResDyVNebfBK"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\">\n",
        "<b>Note:</b> Uncomment and run the next cell if you have not previously installed the libraries.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXPoUK1qbfBK"
      },
      "source": [
        "<b>Installing required libraries</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Dt3eppm1bfBK"
      },
      "outputs": [],
      "source": [
        "# !pip install aif360\n",
        "# !pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjFgRHptbfBL"
      },
      "source": [
        "<b>Loading required libraries</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lT_XDI8zbfBL",
        "outputId": "ea1422c5-b3e1-4fce-dff5-b374aeb74493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
            "pip install 'aif360[LawSchoolGPA]'\n",
            "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
            "pip install 'aif360[Reductions]'\n",
            "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
            "pip install 'aif360[Reductions]'\n",
            "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
            "pip install 'aif360[Reductions]'\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "from aif360.datasets import GermanDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from aif360.metrics import ClassificationMetric\n",
        "from aif360.algorithms.preprocessing import Reweighing\n",
        "from aif360.algorithms.inprocessing import MetaFairClassifier\n",
        "from aif360.explainers import MetricTextExplainer, MetricJSONExplainer\n",
        "\n",
        "from aif360.datasets.lime_encoder import LimeEncoder\n",
        "\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Option 1 Google Colab:**<br>\n",
        "Uncomment the following cell to download the dataset in google colab."
      ],
      "metadata": {
        "id": "5GWW3vXKSo6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download the German Credit DataSet\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc\n",
        "!cp german.data /usr/local/lib/python3.9/dist-packages/aif360/data/raw/german/german.data\n",
        "!cp german.doc /usr/local/lib/python3.9/dist-packages/aif360/data/raw/german/german.doc"
      ],
      "metadata": {
        "id": "8mcNotjsPyjZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "779f96d8-75bc-42cc-926a-b59ad73dcfcd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-22 18:47:29--  https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 79793 (78K) [application/x-httpd-php]\n",
            "Saving to: ‘german.data.22’\n",
            "\n",
            "german.data.22      100%[===================>]  77.92K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-03-22 18:47:30 (604 KB/s) - ‘german.data.22’ saved [79793/79793]\n",
            "\n",
            "--2023-03-22 18:47:30--  https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4679 (4.6K) [application/x-httpd-php]\n",
            "Saving to: ‘german.doc.22’\n",
            "\n",
            "german.doc.22       100%[===================>]   4.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-03-22 18:47:30 (90.5 MB/s) - ‘german.doc.22’ saved [4679/4679]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Option 2: Local environment**<br>\n",
        "<div class=\"alert alert-block alert-danger\">\n",
        "<b>Note:</b> If you are working on your local environment you will have to manually add the files \"german.doc\" and \"german.data\" to the folder \n",
        "\"dist-packages/aif360/data/raw/german/\" under your python path.<br> \n",
        "(or write your script to do it deppending on the os/platform you are using)\n",
        "You can find the files in the lab folder on github or download them from: <br>\n",
        "<a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\">https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data</a> <br>\n",
        "<a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc\">https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc</a>\n",
        "</div> "
      ],
      "metadata": {
        "id": "BCKBANQFSY_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your script here"
      ],
      "metadata": {
        "id": "Y55PQoZBeW-Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Pre-Prosessing Biases "
      ],
      "metadata": {
        "id": "FXQEDfvRiCau"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mklh4Zq3izhn"
      },
      "source": [
        "The dataset is already encoded as the algorithms need the dataset to have numerical values and not categorical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3dRLMw84izhn"
      },
      "outputs": [],
      "source": [
        "dataset_orig = GermanDataset(protected_attribute_names=['age'],           # this dataset also contains protected\n",
        "                                                                          # attribute for \"sex\" which we do not\n",
        "                                                                          # which we do not consider in this evaluation \n",
        "                                                                          # as well as its proxy personal_status\n",
        "                             privileged_classes=[lambda x: x >= 25],      #age >=25 is considered privileged\n",
        "                             features_to_drop=['personal_status', 'sex']) # ignore sex-related attributes and proxies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
        "\n",
        "privileged_groups = [{'age': 1}]\n",
        "unprivileged_groups = [{'age': 0}]"
      ],
      "metadata": {
        "id": "P3JSEr6wLCOd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DQhb36cpl5px"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0XN5frLizhq"
      },
      "source": [
        "#### Compute fairness metric on original training dataset\n",
        "In Lab 4, Week 4 you identified 'age' as one of the protected attributes in the german dataset and you defined a privileged and unprivileged categories, we can now use aif360 to detect bias in the dataset.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##### Mean Difference \n",
        "\n",
        "**Definition:** Mean Difference Compares the percentage of favorable results (in the dataset) for the privileged and unprivileged groups, subtracting the former percentage from the latter.\n",
        "\n",
        "The ideal value of this metric is 0.\n",
        "\n",
        "A value < 0 indicates less favorable outcomes for the unprivileged groups.  This is implemented in the method called mean_difference on the BinaryLabelDatasetMetric class.  The code below performs this check and displays the output, showing that the difference is -0.169905."
      ],
      "metadata": {
        "id": "1hXrynCTJt8g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SYCxNwHSizhq",
        "outputId": "eca26d79-480b-4832-9153-112e72c6d418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Original training dataset"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference in mean outcomes between unprivileged and privileged groups = -0.169905\n"
          ]
        }
      ],
      "source": [
        "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "display(Markdown(\"#### Original training dataset\"))\n",
        "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fXk0I0Dizhq"
      },
      "source": [
        "##### Disparate Impact (in Data Labeling)\n",
        "**Definition:** Disparate Impact  is computed as the ratio of rate of favorable outcome (in the dataset) for the unprivileged group to that of the privileged group. The ideal value of this metric is 1.0.\n",
        "\n",
        "A value < 1 implies higher benefit for the privileged group and a value >1 implies a higher benefit for the unprivileged group."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lu8OAj2eizhq",
        "outputId": "00df3e51-f13c-482d-c1b6-9526198c6afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Original training dataset"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disparate Impact = 0.766430\n"
          ]
        }
      ],
      "source": [
        "display(Markdown(\"#### Original training dataset\"))\n",
        "print(\"Disparate Impact = %f\" % metric_orig_train.disparate_impact())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRYvgPXgizhr"
      },
      "source": [
        "##### Explainers\n",
        "\n",
        "These briefly explain what a metric is and/or how it is calculated unless it is obvious (e.g. accuracy) and print the value.\n",
        "\n",
        "This class contains text `MetricTextExplainer` or JSON `MetricJSONExplainer` formatted explanations for all metric values regardless of which subclass they appear in. This will raise an error if the metric does not apply (e.g. calling true_positive_rate if type(metric) == DatasetMetric)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Text Explanations***"
      ],
      "metadata": {
        "id": "BsZSjegbJ3MJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SQTLMC8Gizhr"
      },
      "outputs": [],
      "source": [
        "text_expl = MetricTextExplainer(metric_orig_train)\n",
        "json_expl = MetricJSONExplainer(metric_orig_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tkmFSUk_izhr",
        "outputId": "f73818a2-291d-49ec-b2d2-1bc453d0a048",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean difference (mean label value on unprivileged instances - mean label value on privileged instances): -0.1699054740619017\n"
          ]
        }
      ],
      "source": [
        "print(text_expl.mean_difference())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LPpIVxmaizhr",
        "outputId": "9b920df6-b6e4-44d7-d8e6-f820118cf7a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disparate impact (probability of favorable outcome for unprivileged instances / probability of favorable outcome for privileged instances): 0.7664297113013201\n"
          ]
        }
      ],
      "source": [
        "print(text_expl.disparate_impact())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJCchLRvizhr"
      },
      "source": [
        "***JSON Explanations***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3cqb1wNlizhr"
      },
      "outputs": [],
      "source": [
        "def format_json(json_str):\n",
        "    return json.dumps(json.loads(json_str, object_pairs_hook=OrderedDict), indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1K3PRv21izhs",
        "outputId": "73203452-458d-484e-ef1b-6859c935718b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"metric\": \"Mean Difference\",\n",
            "  \"message\": \"Mean difference (mean label value on unprivileged instances - mean label value on privileged instances): -0.1699054740619017\",\n",
            "  \"numPositivesUnprivileged\": 63.0,\n",
            "  \"numInstancesUnprivileged\": 113.0,\n",
            "  \"numPositivesPrivileged\": 427.0,\n",
            "  \"numInstancesPrivileged\": 587.0,\n",
            "  \"description\": \"Computed as the difference of the rate of favorable outcomes received by the unprivileged group to the privileged group.\",\n",
            "  \"ideal\": \"The ideal value of this metric is 0.0\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(format_json(json_expl.mean_difference()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yZqbjCwIizhs",
        "outputId": "3d41e919-2473-4c45-db17-632073d6b13d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"metric\": \"Disparate Impact\",\n",
            "  \"message\": \"Disparate impact (probability of favorable outcome for unprivileged instances / probability of favorable outcome for privileged instances): 0.7664297113013201\",\n",
            "  \"numPositivePredictionsUnprivileged\": 63.0,\n",
            "  \"numUnprivileged\": 113.0,\n",
            "  \"numPositivePredictionsPrivileged\": 427.0,\n",
            "  \"numPrivileged\": 587.0,\n",
            "  \"description\": \"Computed as the ratio of rate of favorable outcome for the unprivileged group to that of the privileged group.\",\n",
            "  \"ideal\": \"The ideal value of this metric is 1.0 A value < 1 implies higher benefit for the privileged group and a value >1 implies a higher benefit for the unprivileged group.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(format_json(json_expl.disparate_impact()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6z_r6oQYizhs"
      },
      "source": [
        "#### Mitigate bias by transforming the original dataset\n",
        "The previous step showed that the privileged group was getting 17% more positive outcomes in the training dataset.   Since this is not desirable, we are going to try to mitigate this bias in the training dataset.  As stated above, this is called _pre-processing_ mitigation because it happens before the creation of the model.  \n",
        "\n",
        "AI Fairness 360 implements several pre-processing mitigation algorithms.  We will choose the Reweighing algorithm [1], which is implemented in the `Reweighing` class in the `aif360.algorithms.preprocessing` package.  This algorithm will transform the dataset to have more equity in positive outcomes on the protected attribute for the privileged and unprivileged groups.\n",
        "\n",
        "We then call the fit and transform methods to perform the transformation, producing a newly transformed training dataset (dataset_transf_train).\n",
        "\n",
        "`[1] F. Kamiran and T. Calders,  \"Data Preprocessing Techniques for Classification without Discrimination,\" Knowledge and Information Systems, 2012.`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCHuQixcizhs"
      },
      "source": [
        "##### ***Reweighing***\n",
        "\n",
        "Reweighing is a data preprocessing technique that recommends generating weights for the training examples in each (group, label) combination differently to ensure fairness before classification. The idea is to apply appropriate weights to different tuples in the training dataset to make the training dataset discrimination free with respect to the sensitive attributes. Instead of reweighing, one could also apply techniques (non-discrimination constraints) such as suppression (remove sensitive attributes) or massaging the dataset — modify the labels (change the labels appropriately to remove discrimination from the training data). However, the reweighing technique is more effective than the other two mentioned earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JKIUfO1Eizhs"
      },
      "outputs": [],
      "source": [
        "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
        "                privileged_groups=privileged_groups)\n",
        "dataset_transf_train = RW.fit_transform(dataset_orig_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oagCoduEizhs",
        "outputId": "dc6b7067-d85c-47b8-d896-7f229c6dfc71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.96229508, 1.25555556, 0.678     ,\n",
              "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 1.100625  ,\n",
              "       0.96229508, 1.25555556, 1.100625  , 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       1.100625  , 0.96229508, 0.96229508, 0.96229508, 0.678     ,\n",
              "       0.96229508, 0.96229508, 0.678     , 1.100625  , 0.96229508,\n",
              "       0.678     , 0.96229508, 0.96229508, 1.100625  , 0.96229508,\n",
              "       1.100625  , 0.96229508, 0.96229508, 1.25555556, 0.96229508,\n",
              "       0.678     , 1.100625  , 0.96229508, 0.96229508, 1.25555556,\n",
              "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 1.100625  ,\n",
              "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       1.100625  , 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.96229508, 1.100625  , 0.678     , 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 1.25555556,\n",
              "       1.100625  , 0.96229508, 1.100625  , 1.100625  , 0.96229508,\n",
              "       0.96229508, 0.96229508, 1.25555556, 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.678     , 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       1.100625  , 0.96229508, 0.96229508, 1.25555556, 0.96229508,\n",
              "       0.96229508, 1.25555556, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.96229508, 1.100625  , 1.100625  , 0.96229508,\n",
              "       0.96229508, 1.100625  , 1.100625  , 1.25555556, 0.96229508,\n",
              "       0.96229508, 1.100625  , 0.96229508, 0.96229508, 1.25555556,\n",
              "       1.100625  , 0.96229508, 1.25555556, 1.100625  , 0.96229508,\n",
              "       0.96229508, 1.25555556, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.678     , 0.96229508, 0.678     , 0.96229508, 0.96229508,\n",
              "       1.100625  , 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       1.25555556, 0.96229508, 0.96229508, 0.678     , 1.100625  ,\n",
              "       1.100625  , 0.96229508, 0.96229508, 1.100625  , 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.96229508, 1.100625  , 0.96229508,\n",
              "       0.96229508, 1.100625  , 0.96229508, 0.96229508, 0.96229508,\n",
              "       1.100625  , 0.96229508, 0.96229508, 1.100625  , 1.100625  ,\n",
              "       1.100625  , 1.100625  , 0.96229508, 1.100625  , 0.96229508,\n",
              "       0.96229508, 1.25555556, 0.96229508, 1.100625  , 0.96229508,\n",
              "       0.678     , 1.100625  , 1.100625  , 0.96229508, 1.25555556,\n",
              "       0.96229508, 0.96229508, 0.96229508, 1.100625  , 0.96229508,\n",
              "       0.678     , 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       1.100625  , 1.100625  , 1.100625  , 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.678     , 0.96229508, 1.100625  , 0.96229508,\n",
              "       0.96229508, 1.100625  , 0.678     , 1.100625  , 1.25555556,\n",
              "       0.96229508, 1.100625  , 0.96229508, 0.96229508, 0.96229508,\n",
              "       1.100625  , 0.96229508, 1.100625  , 0.96229508, 0.96229508,\n",
              "       1.25555556, 0.96229508, 0.96229508, 0.96229508, 0.678     ,\n",
              "       0.678     , 0.96229508, 1.25555556, 0.96229508, 0.96229508,\n",
              "       0.96229508, 1.25555556, 1.100625  , 1.100625  , 1.25555556,\n",
              "       0.96229508, 0.678     , 1.100625  , 0.96229508, 1.100625  ,\n",
              "       1.25555556, 0.96229508, 0.96229508, 0.96229508, 1.100625  ,\n",
              "       1.100625  , 0.96229508, 0.96229508, 1.100625  , 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.96229508, 1.25555556, 0.96229508, 0.96229508,\n",
              "       1.100625  , 0.96229508, 0.678     , 0.96229508, 1.100625  ,\n",
              "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.96229508, 1.100625  , 1.100625  ,\n",
              "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 1.100625  ,\n",
              "       1.25555556, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.96229508, 1.25555556, 0.96229508, 1.100625  ,\n",
              "       1.25555556, 0.678     , 0.96229508, 1.100625  , 1.100625  ,\n",
              "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 0.96229508,\n",
              "       1.25555556, 1.100625  , 1.100625  , 1.100625  , 0.96229508,\n",
              "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 1.25555556,\n",
              "       0.96229508, 1.25555556, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.96229508, 1.100625  , 0.96229508,\n",
              "       1.100625  , 0.96229508, 1.100625  , 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 1.100625  , 0.96229508, 1.100625  , 1.25555556,\n",
              "       1.100625  , 0.96229508, 0.678     , 1.25555556, 0.96229508,\n",
              "       0.678     , 1.100625  , 0.96229508, 1.100625  , 1.100625  ,\n",
              "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.96229508, 1.100625  , 1.100625  , 1.25555556,\n",
              "       1.25555556, 0.96229508, 1.100625  , 1.100625  , 0.96229508,\n",
              "       0.96229508, 1.100625  , 0.96229508, 1.100625  , 0.678     ,\n",
              "       0.96229508, 1.100625  , 0.96229508, 1.25555556, 0.96229508,\n",
              "       1.100625  , 0.678     , 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.678     , 1.25555556, 0.96229508, 1.25555556, 0.678     ,\n",
              "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 0.678     ,\n",
              "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 1.100625  ,\n",
              "       0.96229508, 0.96229508, 0.678     , 1.25555556, 1.100625  ,\n",
              "       0.96229508, 0.96229508, 0.678     , 0.96229508, 0.96229508,\n",
              "       1.100625  , 1.100625  , 0.96229508, 1.100625  , 1.100625  ,\n",
              "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.678     ,\n",
              "       0.96229508, 0.96229508, 0.96229508, 1.25555556, 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.678     , 0.96229508, 1.100625  ,\n",
              "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 1.100625  , 0.96229508, 1.100625  , 0.678     ,\n",
              "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.96229508, 1.25555556, 0.678     , 1.100625  ,\n",
              "       0.96229508, 1.100625  , 0.96229508, 1.100625  , 0.96229508,\n",
              "       1.25555556, 0.96229508, 0.96229508, 1.25555556, 1.100625  ,\n",
              "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 1.25555556, 0.96229508, 0.96229508, 0.678     ,\n",
              "       1.100625  , 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 1.25555556, 1.100625  , 0.96229508, 0.96229508,\n",
              "       0.96229508, 1.25555556, 0.96229508, 0.96229508, 1.100625  ,\n",
              "       0.96229508, 1.100625  , 1.25555556, 0.96229508, 1.100625  ,\n",
              "       1.25555556, 0.96229508, 1.100625  , 0.96229508, 0.96229508,\n",
              "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 1.100625  ,\n",
              "       1.100625  , 0.96229508, 0.96229508, 0.96229508, 0.678     ,\n",
              "       0.96229508, 0.96229508, 0.96229508, 1.100625  , 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.96229508, 1.25555556, 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 1.100625  , 1.100625  , 0.96229508, 0.96229508,\n",
              "       0.96229508, 1.25555556, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 1.100625  , 0.96229508, 0.96229508, 1.25555556,\n",
              "       0.96229508, 1.100625  , 1.100625  , 0.96229508, 0.96229508,\n",
              "       1.25555556, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.678     , 0.96229508, 1.100625  , 1.25555556, 0.96229508,\n",
              "       0.96229508, 0.96229508, 1.25555556, 0.678     , 0.96229508,\n",
              "       0.96229508, 1.25555556, 0.678     , 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 1.100625  ,\n",
              "       0.96229508, 0.678     , 1.100625  , 1.100625  , 1.100625  ,\n",
              "       0.96229508, 1.100625  , 0.96229508, 1.100625  , 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.96229508, 0.678     , 1.100625  ,\n",
              "       0.96229508, 0.96229508, 0.678     , 1.25555556, 0.96229508,\n",
              "       0.96229508, 0.96229508, 1.100625  , 0.96229508, 1.100625  ,\n",
              "       1.100625  , 0.96229508, 0.678     , 0.96229508, 0.96229508,\n",
              "       1.100625  , 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       1.100625  , 0.96229508, 0.678     , 1.100625  , 1.100625  ,\n",
              "       0.678     , 0.96229508, 1.100625  , 0.96229508, 0.678     ,\n",
              "       0.96229508, 1.25555556, 0.678     , 1.25555556, 0.96229508,\n",
              "       0.96229508, 0.96229508, 1.100625  , 0.96229508, 0.96229508,\n",
              "       1.100625  , 1.100625  , 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 1.100625  ,\n",
              "       0.96229508, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.678     , 1.25555556, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 0.96229508, 0.96229508, 0.678     , 0.96229508,\n",
              "       0.96229508, 1.100625  , 0.678     , 1.100625  , 1.100625  ,\n",
              "       1.25555556, 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       0.96229508, 1.100625  , 0.96229508, 0.96229508, 1.100625  ,\n",
              "       1.100625  , 0.96229508, 0.96229508, 0.96229508, 0.96229508,\n",
              "       1.100625  , 0.96229508, 1.25555556, 1.100625  , 0.96229508,\n",
              "       0.678     , 0.96229508, 1.25555556, 0.96229508, 0.96229508,\n",
              "       0.678     , 1.25555556, 1.25555556, 0.96229508, 0.96229508,\n",
              "       0.96229508, 1.100625  , 0.96229508, 1.100625  , 0.96229508,\n",
              "       1.100625  , 1.100625  , 1.100625  , 1.100625  , 0.96229508,\n",
              "       0.96229508, 1.100625  , 1.100625  , 0.96229508, 0.96229508,\n",
              "       0.96229508, 1.25555556, 1.25555556, 0.96229508, 0.96229508])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "dataset_transf_train.instance_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nrkMkA9Vizhs",
        "outputId": "1b0fa75c-ed22-43d7-e0ab-2cdf1f9adfc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "700"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "len(dataset_transf_train.instance_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ce5I5utizhs"
      },
      "source": [
        "#### Compute fairness metric on transformed dataset\n",
        "Now that we have a transformed dataset, we can check how effective it was in removing bias by using the same metric we used for the original training dataset in Step 3.  Once again, we use the function mean_difference in the BinaryLabelDatasetMetric class.   We see the mitigation step was very effective, the difference in mean outcomes is now 0.0.  So we went from a 17% advantage for the privileged group to equality in terms of mean outcome."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Mean Difference "
      ],
      "metadata": {
        "id": "uWrjSYNFKPZI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wqUvvlzOizhs",
        "outputId": "07758e69-f9f3-41cf-8fbd-2a84f00b45dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Transformed training dataset"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference in mean outcomes between unprivileged and privileged groups = 0.000000\n"
          ]
        }
      ],
      "source": [
        "metric_transf_train = BinaryLabelDatasetMetric(dataset_transf_train, \n",
        "                                               unprivileged_groups=unprivileged_groups,\n",
        "                                               privileged_groups=privileged_groups)\n",
        "display(Markdown(\"#### Transformed training dataset\"))\n",
        "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_transf_train.mean_difference())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Disparate Impact"
      ],
      "metadata": {
        "id": "oV40auQGKUqn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "a4ydl8ZIizhs",
        "outputId": "94068bd9-9db9-4a95-dc1d-61deb0d18655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "#### Transformed training dataset"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disparate Impact = 1.000000\n"
          ]
        }
      ],
      "source": [
        "display(Markdown(\"#### Transformed training dataset\"))\n",
        "print(\"Disparate Impact = %f\" % metric_transf_train.disparate_impact())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G1lyUf2bfBO"
      },
      "source": [
        "### Step 3: In-Prosessing Biases "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INV6y8nhbfBO"
      },
      "source": [
        "<b>Preparation for training a classifier.</b><br>\n",
        "We will  divide the dataset into a training and a test subsets.\n",
        "We define them respectively as 70% and 30% of the whole data.\n",
        "We will use the following code to do so."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1xFlmoJ1bfBO"
      },
      "outputs": [],
      "source": [
        "dataset_gcredit_train, dataset_gcredit_test = dataset_orig.split([0.7], shuffle=True)\n",
        "\n",
        "privileged_groups = [{'age': 1}]\n",
        "unprivileged_groups = [{'age': 0}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCARTG18bfBO"
      },
      "source": [
        "#### Compute Faireness of the model before mitigation\n",
        "Below we are using several faireness metrics from AIF360 toolkint to evaluate fairenesse metrics before appling the inprocessing mitigation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eyhc9MTYbfBO"
      },
      "source": [
        "Build a classifier without fairness constraints (tau penalty = 0 see [MetaFairClassifier documentation](https://aif360.readthedocs.io/en/stable/modules/generated/aif360.algorithms.inprocessing.MetaFairClassifier.html#aif360.algorithms.inprocessing.MetaFairClassifier))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "BEUBFyPzbfBO"
      },
      "outputs": [],
      "source": [
        "biased_model = MetaFairClassifier(tau=0, sensitive_attr=\"age\", type=\"fdr\").fit(dataset_gcredit_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWnew4t6bfBO"
      },
      "source": [
        "Apply the unconstrained model to test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "UvMhkSTIbfBO"
      },
      "outputs": [],
      "source": [
        "dataset_bias_test = biased_model.predict(dataset_gcredit_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTkW1eakbfBO"
      },
      "source": [
        "Test the \"biased\" classifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric_orig_test = BinaryLabelDatasetMetric(dataset_gcredit_test, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = {:.3f}\".format(metric_orig_test.mean_difference()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rnxqmifHPEg",
        "outputId": "355248d8-420d-4f55-8c2a-0ce55b782b2a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIkHV5N6bfBO",
        "outputId": "eca8ae38-4131-482e-81f9-22fe0a632ec5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Classification accuracy = 0.537\n",
            "Test set: Balanced classification accuracy = 0.440\n",
            "Test set: Disparate impact = 0.952\n",
            "Test set: False discovery rate ratio = 0.634\n"
          ]
        }
      ],
      "source": [
        "classified_metric_bias_test = ClassificationMetric(dataset_gcredit_test, dataset_bias_test,\n",
        "                                                   unprivileged_groups=unprivileged_groups,\n",
        "                                                   privileged_groups=privileged_groups)\n",
        "print(\"Test set: Classification accuracy = {:.3f}\".format(classified_metric_bias_test.accuracy()))\n",
        "TPR = classified_metric_bias_test.true_positive_rate()\n",
        "TNR = classified_metric_bias_test.true_negative_rate()\n",
        "bal_acc_bias_test = 0.5*(TPR+TNR)\n",
        "print(\"Test set: Balanced classification accuracy = {:.3f}\".format(bal_acc_bias_test))\n",
        "print(\"Test set: Disparate impact = {:.3f}\".format(classified_metric_bias_test.disparate_impact()))\n",
        "fdr = classified_metric_bias_test.false_discovery_rate_ratio()\n",
        "fdr = min(fdr, 1/fdr)\n",
        "print(\"Test set: False discovery rate ratio = {:.3f}\".format(fdr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSgzsreobfBO"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b> Tip: </b> Make use of the documentation of <a href=https://aif360.readthedocs.io/en/latest/index.html><b>AIF360</b></a>, and your own search to understaind the metrics and to be able to interpret them.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBm3kMwObfBP"
      },
      "source": [
        "In the following we will apply an in-processing bias mitigation technique <b><i>\"Meta-Algorithm for fair classification\"</i></b>. This technique operates with a faireness constraint i.e., by optimising for faireness metrics. You can read more about it <a href=https://arxiv.org/pdf/1806.06055.pdf>[HERE]</a><br>\n",
        "For this example we will to optimize for the ***the fals discovery rate (fdr)*** and sensitive attribute ***age***\n",
        "\n",
        "(Optional) You can also try **statistical rate/disparate impact (sr)** and sensitive attribute ***age***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimising for False Discovery Rate (FDR) and Re-compute Faireness"
      ],
      "metadata": {
        "id": "P_wzTmf8RJOK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    \n",
        "A. Apply the debiased model to training data and train the classifier with the selected fairness constrain"
      ],
      "metadata": {
        "id": "EZmHhaOdRNX3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "N1y99Vh8bfBP"
      },
      "outputs": [],
      "source": [
        "fdr_optimised_model = MetaFairClassifier(tau=0.5, sensitive_attr=\"age\", type=\"fdr\").fit(dataset_gcredit_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwBSr_IJbfBP"
      },
      "source": [
        "B. Apply the debiased classifier to test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4tphSAYGbfBP"
      },
      "outputs": [],
      "source": [
        "fdr_optimised_prediction = fdr_optimised_model.predict(dataset_gcredit_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7GnyUYZbfBP"
      },
      "source": [
        "C. Compute the same faireness metrics for new classifier (with fairness constraint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AmZnJWFbfBP",
        "outputId": "d67fb2d3-f39e-4dbb-af83-2c15f49addae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.010\n"
          ]
        }
      ],
      "source": [
        "fdr_optimised_metric = BinaryLabelDatasetMetric(fdr_optimised_prediction, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = {:.3f}\".format(fdr_optimised_metric.mean_difference()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERoWrujZbfBP",
        "outputId": "70e00718-2850-4bfd-bb63-5af3fb2bdc35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Classification accuracy = 0.520\n",
            "Test set: Balanced classification accuracy = 0.426\n",
            "Test set: Disparate impact = 0.986\n",
            "Test set: False discovery rate ratio = 0.566\n"
          ]
        }
      ],
      "source": [
        "fdr_optimised_classification = ClassificationMetric(dataset_gcredit_test, \n",
        "                                                 fdr_optimised_prediction,\n",
        "                                                 unprivileged_groups=unprivileged_groups,\n",
        "                                                 privileged_groups=privileged_groups)\n",
        "print(\"Test set: Classification accuracy = {:.3f}\".format(fdr_optimised_classification.accuracy()))\n",
        "TPR = fdr_optimised_classification.true_positive_rate()\n",
        "TNR = fdr_optimised_classification.true_negative_rate()\n",
        "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
        "print(\"Test set: Balanced classification accuracy = {:.3f}\".format(bal_acc_debiasing_test))\n",
        "print(\"Test set: Disparate impact = {:.3f}\".format(fdr_optimised_classification.disparate_impact()))\n",
        "fdr = fdr_optimised_classification.false_discovery_rate_ratio()\n",
        "fdr = min(fdr, 1/fdr)\n",
        "print(\"Test set: False discovery rate ratio = {:.3f}\".format(fdr))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimising for Disaparate Impact (SR) and Re-compute Faireness"
      ],
      "metadata": {
        "id": "5qlbkZrVQ_0G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    \n",
        "A. Apply the debiased model to training data and train the classifier with the selected fairness constrain. The value of `tau` should be different from `0` We choose thos value after several tests"
      ],
      "metadata": {
        "id": "a3m9A0yXdI2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sr_optimised_model = MetaFairClassifier(tau=0.3, sensitive_attr=\"age\", type=\"sr\").fit(dataset_gcredit_train)"
      ],
      "metadata": {
        "id": "OrLL-dHXQqyq"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hyLuCjqdI2z"
      },
      "source": [
        "B. Apply the debiased classifier to test data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sr_optimised_predictions = sr_optimised_model.predict(dataset_gcredit_test)"
      ],
      "metadata": {
        "id": "_F4IFSs5Qx3y"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmOaqX1ZdI2z"
      },
      "source": [
        "C. Compute the same faireness metrics for new classifier (with fairness constraint)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sr_optimised_metric = BinaryLabelDatasetMetric(sr_optimised_predictions, \n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = {:.3f}\".format(sr_optimised_metric.mean_difference()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCUEeuv9QyXW",
        "outputId": "d7805d56-5f9d-4051-d8a4-c4b9cc3c7602"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Difference in mean outcomes between unprivileged and privileged groups = 0.121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classified_metric_debiasing_test = ClassificationMetric(dataset_gcredit_test, \n",
        "                                                 sr_optimised_predictions,\n",
        "                                                 unprivileged_groups=unprivileged_groups,\n",
        "                                                 privileged_groups=privileged_groups)\n",
        "print(\"Test set: Classification accuracy = {:.3f}\".format(classified_metric_debiasing_test.accuracy()))\n",
        "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
        "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
        "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
        "print(\"Test set: Balanced classification accuracy = {:.3f}\".format(bal_acc_debiasing_test))\n",
        "print(\"Test set: Disparate impact (Classification) = {:.3f}\".format(classified_metric_debiasing_test.disparate_impact()))\n",
        "fdr = classified_metric_debiasing_test.false_discovery_rate_ratio()\n",
        "fdr = min(fdr, 1/fdr)\n",
        "print(\"Test set: False discovery rate ratio = {:.3f}\".format(fdr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3J8YZFYQ5uW",
        "outputId": "ee481c57-4c66-4987-90c6-6e22c6ef0450"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Classification accuracy = 0.450\n",
            "Test set: Balanced classification accuracy = 0.369\n",
            "Test set: Disparate impact (Classification) = 1.203\n",
            "Test set: False discovery rate ratio = 0.484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUYXBlZAbfBP"
      },
      "source": [
        "<br><br>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}